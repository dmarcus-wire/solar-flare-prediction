{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b96a4e3-8ba1-492f-89bf-32d421ab2785",
   "metadata": {},
   "source": [
    "# Gong Data Archive\n",
    "\n",
    "## Data source:\n",
    "\n",
    "1. The Gong2 data is hosted here: https://gong2.nso.edu/archive/patch.pl?menutype=s. \n",
    "1. There is an FTP site organized with different subfolders: https://nispdata.nso.edu/ftp/\n",
    "1. Ddata fetch initially from https://nispdata.nso.edu/ftp/oQR/zqa/202402/\n",
    "\n",
    "## Subfolder breakdown:\n",
    "\n",
    "1. `oQR` [1] refers to Quick-Reduce Outputs refers to outputs produced each minute, weather permitting, the GONG network observes the Sun at two spectral wavelengths: 676.78nm (a Ni I absorption line) and 656.28nm (the H-alpha absorption line).\n",
    "1. `zqa` is a filetype, because GONG was not originally designed for precise calibration and removal of non-solar magnetic field bias, a separate zeropoint corrected (ZPC) “zqa” [2] file is [normally] created from each “bqa”. The two are identical except for the subtraction of a planar zeropoint correction.\n",
    "1. `202402` YYYYMM data around Feburary 22, 2024, when the three top-tier X-class solar flares launched off the sun\n",
    "1. The GONG network has telescopes strategically placed at six locations around the world. Each site represents one of the six longitudal bands that allows the network to make 24-hour a day observations of the Sun. Current coverage with the network is around 87%. Subfolders [3] correspond to the 6x locations:\n",
    "1. bb = Big Bear Solar Observatory, California\n",
    "1. ct = Cerro Tololo Interamerican Observatory, Chile\n",
    "1. le = Learmonth Solar Observatory, Australia\n",
    "1. td = El Teide Observatory, Canary Islands\n",
    "1. ud = Udaipur Solar Observatory, India\n",
    "1. ?? = Mauna Loa Observatory, Hawaii, USA\n",
    "\n",
    "# References\n",
    "- [1] https://catalog.data.gov/dataset/global-oscillation-network-group-gong-quick-reduce-outputs-oqr\n",
    "- [2] https://ccmc.gsfc.nasa.gov/static/files/CCMC_SWPC_annex_final_report.pdf\n",
    "- [3] https://nso.edu/telescopes/nisp/gong/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5a9815-6970-47ee-a740-4d53f340edf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/app-root/lib/python3.9/site-packages (24.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip && pip install requests beautifulsoup4 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2a216b-1d08-47a2-a300-bd4b7a369cd6",
   "metadata": {},
   "source": [
    "# Fetch data\n",
    "\n",
    "To download all the files in the folders that contain \"dim-860.jpg\" from https://nispdata.nso.edu/ftp/oQR/zqa/202402/, I used BeautifulSoup libraries to scrape the webpage for links. Then, I use the os and shutil libraries to create directories and download the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ea47d-5d0c-4e71-bdd8-fda0443aaf8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing folders:  47%|████▋     | 63/135 [14:50<31:18, 26.09s/it]"
     ]
    }
   ],
   "source": [
    "# %%writefile ../scripts/fetch_data.py\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# The base URL of the directory is specified.\n",
    "base_url = 'https://nispdata.nso.edu/ftp/oQR/zqa/202402/'\n",
    "\n",
    "# Ensure the data is defined\n",
    "data = '../data/raw'  # Define your data path here\n",
    "\n",
    "# Downloads a file from a given URL and saves it to a specified folder.\n",
    "def download_file(url, dest_folder):\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "    file_name = url.split('/')[-1]\n",
    "    file_path = os.path.join(dest_folder, file_name)\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(file_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                f.write(chunk)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Finds all subfolders in the base URL that contain the target file (dim-860.jpg)\n",
    "def find_folders_with_file(url, target_file):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    folders = []\n",
    "    \n",
    "    for link in soup.find_all('a'):\n",
    "        href = link.get('href')\n",
    "        if href.endswith('/'):\n",
    "            folder_url = url + href\n",
    "            folder_response = requests.get(folder_url)\n",
    "            folder_soup = BeautifulSoup(folder_response.text, 'html.parser')\n",
    "            if any(target_file in a.get('href') for a in folder_soup.find_all('a')):\n",
    "                folders.append(folder_url)\n",
    "    return folders\n",
    "\n",
    "# Downloads only the files containing 'dim-860.jpg' from the identified folders into a single folder\n",
    "def download_files_from_folders(folders, target_file, dest_folder):\n",
    "    file_count = 0\n",
    "    for folder in tqdm(folders, desc=\"Processing folders\"):\n",
    "        response = requests.get(folder)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        for link in soup.find_all('a'):\n",
    "            file_href = link.get('href')\n",
    "            if target_file in file_href and not file_href.endswith('/'):\n",
    "                file_url = folder + file_href\n",
    "                if download_file(file_url, dest_folder):\n",
    "                    file_count += 1\n",
    "    return file_count\n",
    "\n",
    "# Starts by specifying the target file and then finds the relevant folders. Finally, it downloads all the files from these folders into a single folder\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "    target_file = 'dim-860.jpg'\n",
    "    folders = find_folders_with_file(base_url, target_file)\n",
    "    file_count = download_files_from_folders(folders, target_file, data)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Total files downloaded: {file_count}\")\n",
    "    print(f\"Time taken: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce7319-78de-45ff-86da-65913ea895bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run ../scripts/fetch_data.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
